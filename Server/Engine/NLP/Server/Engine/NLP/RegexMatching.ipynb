{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2117ad0e-ec28-4908-85ee-d62d41210a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37422c2c-b38b-4f52-9308-ffa436ff2129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. False\n",
      "Strange False\n",
      "loves False\n",
      "Samosa False\n",
      "so False\n",
      "much False\n",
      "that False\n",
      "he False\n",
      "can False\n",
      "sell False\n",
      "almonds False\n",
      "for False\n",
      "himself False\n",
      ". False\n",
      "Somehow False\n",
      "people False\n",
      "find False\n",
      "it False\n",
      "new False\n",
      "... False\n",
      "https://www.sharma.com/8000 True\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"Dr. Strange loves Samosa so much that he can sell almonds for himself. Somehow people find it new... https://www.sharma.com/8000\")\n",
    "for token in doc:\n",
    "    print(token, token.like_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86f2f2c4-ebfc-48af-861c-f28f5e11fcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a053831-66ef-439b-822e-ad9ebe992e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "948f5293-e587-4932-bd36-59ce36a5ae6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x24a91c58170>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x24a91db2390>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x24a91c46570>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x24a86ab89d0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x24a86aaf290>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x24a91c465e0>)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c035087-9f52-4465-9a44-45b95155f0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b60127f-dab6-43bb-ba0b-5f72fd4469fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byju  |  PROPN  |  Byju\n",
      "founded  |  VERB  |  found\n",
      "a  |  DET  |  a\n",
      "company  |  NOUN  |  company\n",
      "called  |  VERB  |  call\n",
      "Byju  |  PROPN  |  Byju\n",
      "Byju  |  ORG Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dr. Strange loves Samosa so much that he can sell almonds for himself. Somehow people find it new... https://www.sharma.com/8000\")\n",
    "doc = nlp(\"Byju founded a company called Byju\")\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.pos_, \" | \", token.lemma_)\n",
    "for ent in doc.ents:\n",
    "    print(ent, \" | \", ent.label_, spacy.explain(ent.label_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5dbcdc4-c3d9-4106-bf74-41ae9d071e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Byju founded a company called \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Byju\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fb6bb330-51e0-4c48-8fa6-88d688e9efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTListIndex, PromptHelper,GPTVectorStoreIndex\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index import LLMPredictor, ServiceContext,StorageContext\n",
    "import torch\n",
    "from langchain.llms.base import LLM\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c271e1b-0fa6-482d-a00e-84914c33c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLLM(LLM):\n",
    "    model_name = \"google/flan-t5-base\"\n",
    "    pipeline = pipeline(\"text2text-generation\", model=model_name, model_kwargs={\"torch_dtype\":torch.bfloat16})\n",
    "\n",
    "    def _call(self, prompt, stop=None):\n",
    "        return self.pipeline(prompt, max_length=9999)[0][\"generated_text\"]\n",
    " \n",
    "    def _identifying_params(self):\n",
    "        return {\"name_of_model\": self.model_name}\n",
    "\n",
    "    def _llm_type(self):\n",
    "        return \"custom\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, str):\n",
    "            return False\n",
    "        return self.model_name == other.model_name\n",
    "\n",
    "llm_predictor = LLMPredictor(llm=customLLM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78b57ea0-9939-4df2-bbd6-c0c6a5711c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hfemb = HuggingFaceEmbeddings()\n",
    "embed_model = LangchainEmbedding(hfemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60b0c845-f910-4fa4-a964-2908e4b6e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"The use of NLP in the realm of financial technology is broad and complex, with applications\n",
    "ranging from sentiment analysis and named entity recognition to question answering. Large\n",
    "Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no\n",
    "LLM specialized for the financial domain has been reported in literature. In this work, we\n",
    "present BloombergGPT, a 50 billion parameter language model that is trained on a wide\n",
    "range of financial data. We construct a 363 billion token dataset based on Bloomberg’s\n",
    "extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345\n",
    "billion tokens from general purpose datasets. We validate BloombergGPT on standard\n",
    "LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most\n",
    "accurately reflect our intended usage. Our mixed dataset training leads to a model that\n",
    "outperforms existing models on financial tasks by significant margins without sacrificing\n",
    "performance on general LLM benchmarks. Additionally, we explain our modeling choices,\n",
    "training process, and evaluation methodology. As a next step, we plan to release training\n",
    "logs (Chronicles) detailing our experience in training BloombergGPT.\n",
    "Snap Inc., the creator of Snapchat, introduced My AI for Snapchat+ this week. The experimental feature is running on ChatGPT API. My AI offers Snapchatters a friendly, customizable chatbot at their fingertips that offers recommendations, and can even write a haiku for friends in seconds. Snapchat, where communication and messaging is a daily behavior, has 750 million monthly Snapchatters.\n",
    "\n",
    "\n",
    "Quizlet Q-Chat, UI screenshot\n",
    "\n",
    "Play video\n",
    "Quizlet Q-Chat\n",
    "\n",
    "Quizlet is a global learning platform with more than 60 million students using it to study, practice and master whatever they’re learning. Quizlet has worked with OpenAI for the last three years, leveraging GPT-3 across multiple use cases, including vocabulary learning and practice tests. With the launch of ChatGPT API, Quizlet is introducing Q-Chat, a fully-adaptive AI tutor that engages students with adaptive questions based on relevant study materials delivered through a fun chat experience.\n",
    "\n",
    "\n",
    "Instacart’s Ask Instacart, UI screenshot\n",
    "Instacart’s Ask Instacart\n",
    "\n",
    "Instacart is augmenting the Instacart app to enable customers to ask about food and get inspirational, shoppable answers. This uses ChatGPT alongside Instacart’s own AI and product data from their 75,000+ retail partner store locations to help customers discover ideas for open-ended shopping goals, such as “How do I make great fish tacos?” or “What’s a healthy lunch for my kids?” Instacart plans to launch “Ask Instacart” later this year.\n",
    "\n",
    "\n",
    "\n",
    "Play video\n",
    "Shopify’s Shop app\n",
    "\n",
    "Shop, Shopify’s consumer app, is used by 100 million shoppers to find and engage with the products and brands they love. ChatGPT API is used to power Shop’s new shopping assistant. When shoppers search for products, the shopping assistant makes personalized recommendations based on their requests. Shop’s new AI-powered shopping assistant will streamline in-app shopping by scanning millions of products to quickly find what buyers are looking for—or help them discover something new.\n",
    "\n",
    "\n",
    "The Speak App, UI screenshot\n",
    "\n",
    "Play video\n",
    "The Speak app\n",
    "\n",
    "Speak is an AI-powered language learning app focused on building the best path to spoken fluency. They’re the fastest-growing English app in South Korea, and are already using the Whisper API to power a new AI speaking companion product, and rapidly bring it to the rest of the globe. Whisper’s human-level accuracy for language learners of every level unlocks true open-ended conversational practice and highly accurate feedback.\n",
    "\n",
    "ChatGPT API\n",
    "Model: The ChatGPT model family we are releasing today, gpt-3.5-turbo, is the same model used in the ChatGPT product. It is priced at \n",
    "OPENAI_API_KEY\"\n",
    "  -H \"Content-Type: application/json\"\n",
    "  -d '{\n",
    "  \"model\": \"gpt-3.5-turbo\",\n",
    "  \"messages\": [{\"role\": \"user\", \"content\": \"What is the OpenAI mission?\"}]\n",
    "}'\n",
    "To learn more about the ChatGPT API, visit our Chat guide.\n",
    "\n",
    "ChatGPT upgrades\n",
    "We are constantly improving our ChatGPT models, and want to make these enhancements available to developers as well. Developers who use the gpt-3.5-turbo model will always get our recommended stable model, while still having the flexibility to opt for a specific model version. For example, today we’re releasing gpt-3.5-turbo-0301, which will be supported through at least June 1st, and we’ll update gpt-3.5-turbo to a new stable release in April. The models page will provide switchover updates.\n",
    "\n",
    "Dedicated instances\n",
    "We are also now offering dedicated instances for users who want deeper control over the specific model version and system performance. By default, requests are run on compute infrastructure shared with other users, who pay per request. Our API runs on Azure, and with dedicated instances, developers will pay by time period for an allocation of compute infrastructure that’s reserved for serving their requests.\n",
    "\n",
    "Developers get full control over the instance’s load (higher load improves throughput but makes each request slower), the option to enable features such as longer context limits, and the ability to pin the model snapshot.\n",
    "\n",
    "Dedicated instances can make economic sense for developers running beyond ~450M tokens per day. Additionally, it enables directly optimizing a developer’s workload against hardware performance, which can dramatically reduce costs relative to shared infrastructure. For dedicated instance inquiries, contact us.\n",
    "\n",
    "Whisper API\n",
    "Whisper, the speech-to-text model we open-sourced in September 2022, has received immense praise from the developer community but can also be hard to run. We’ve now made the large-v2 model available through our API, which gives convenient on-demand access priced at \n",
    "OPENAI_API_KEY\" \\\n",
    "  -H \"Content-Type: multipart/form-data\" \\\n",
    "  -F model=\"whisper-1\" \\\n",
    "  -F file=\"@/path/to/file/openai.mp3\"\n",
    "To learn more about the Whisper API, visit our Speech to Text guide.\n",
    "\n",
    "Developer focus\n",
    "Over the past six months, we’ve been collecting feedback from our API customers to understand how we can better serve them. We’ve made concrete changes, such as:\n",
    "\n",
    "Data submitted through the API is no longer used for service improvements (including model training) unless the organization opts in\n",
    "Implementing a default 30-day data retention policy for API users, with options for stricter retention depending on user needs.\n",
    "Removing our pre-launch review (unlocked by improving our automated monitoring)\n",
    "Improving developer documentation\n",
    "Simplifying our Terms of Service and Usage Policies, including terms around data ownership: users own the input and output of the models.\n",
    "For the past two months our uptime has not met our own expectations nor that of our users. Our engineering team’s top priority is now stability of production use cases—we know that ensuring AI benefits all of humanity requires being a reliable service provider. Please hold us accountable for improved uptime over the upcoming months!\n",
    "\n",
    "We believe that AI can provide incredible opportunities and economic empowerment to everyone, and the best way to achieve\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f560c380-a657-4554-9f79-ef371716d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set number of output tokens\n",
    "# num_output = 500\n",
    "# # set maximum input size\n",
    "# max_input_size = 512\n",
    "# # set maximum chunk overlap\n",
    "# max_chunk_overlap = 15\n",
    "\n",
    "\n",
    "# prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e971f1b6-ed29-4182-a8fc-b306aabdeabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('Student').load_data()\n",
    "# from llama_index import Document\n",
    "\n",
    "# text_list = [text1]\n",
    "\n",
    "# documents = [Document(t) for t in text_list]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "186fea09-f24b-407b-b8cc-eaca7d804ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index = GPTSimpleVectorIndex(documents, embed_model=embed_model, llm_predictor=llm_predictor)\n",
    "\n",
    "#index = GPTListIndex(documents, embed_model=embed_model, llm_predictor=llm_predictor)\n",
    "\n",
    "#index.save_to_disk('index.json')\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, embed_model=embed_model)\n",
    "index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54ae17e8-41b4-4bc0-8ca1-edba9f8fa9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f9da71a-2405-488b-8313-b1d2fa5ee6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_add_nodes_to_index',\n",
       " '_aget_node_with_embedding',\n",
       " '_async_add_nodes_to_index',\n",
       " '_build_index_from_nodes',\n",
       " '_delete_node',\n",
       " '_docstore',\n",
       " '_get_node_with_embedding',\n",
       " '_graph_store',\n",
       " '_index_struct',\n",
       " '_insert',\n",
       " '_is_protocol',\n",
       " '_service_context',\n",
       " '_show_progress',\n",
       " '_storage_context',\n",
       " '_store_nodes_override',\n",
       " '_use_async',\n",
       " '_vector_store',\n",
       " 'as_chat_engine',\n",
       " 'as_query_engine',\n",
       " 'as_retriever',\n",
       " 'build_index_from_nodes',\n",
       " 'delete',\n",
       " 'delete_nodes',\n",
       " 'delete_ref_doc',\n",
       " 'docstore',\n",
       " 'from_documents',\n",
       " 'from_vector_store',\n",
       " 'index_id',\n",
       " 'index_struct',\n",
       " 'index_struct_cls',\n",
       " 'insert',\n",
       " 'insert_nodes',\n",
       " 'ref_doc_info',\n",
       " 'refresh',\n",
       " 'refresh_ref_docs',\n",
       " 'service_context',\n",
       " 'set_index_id',\n",
       " 'storage_context',\n",
       " 'summary',\n",
       " 'update',\n",
       " 'update_ref_doc',\n",
       " 'vector_store']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response = index.storage_context.search(\"What's the cost of Whisper model?\")\n",
    "dir(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1927c50-4ec2-4e8f-8a16-d8f91709b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b2a5b-a244-45da-b475-9577282c96d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp fix for running shell commands on Google Colab\n",
    "\n",
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f7bf2-f996-4b16-9741-fc07a2fd9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install gradio -q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
